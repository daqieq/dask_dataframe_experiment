{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask DataFrame Experiment\n",
    "\n",
    "## Part 2\n",
    "\n",
    "Use Pandas only to convert a pandas dataframe into a text file in 'fixed position' format, with custom encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# %config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom data encoding helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EBCDIC:\n",
    "    \n",
    "    def __init__(self, logger, cp='cp037'):\n",
    "        self.logger = logger\n",
    "        self.cp = cp\n",
    "        self.cp_blank = ' '.encode(cp)\n",
    "    \n",
    "    def _log_error_msg1(msg: str):\n",
    "        self.logger(f\"ERROR: Function ::{msg}:: Returned error.\")\n",
    "        \n",
    "    def _log_error_msg2(msg: tuple):\n",
    "        self.logger(f\"ERROR: Function ::{msg[0]}:: {msg[1]}.\")\n",
    "    \n",
    "    def to_char(self, string, size) -> bytes:\n",
    "        try:\n",
    "            s = string.encode(self.cp)[:size]\n",
    "            if len(s) < size:\n",
    "                s += self.cp_blank * (size - len(s))\n",
    "            return s\n",
    "        except:\n",
    "            self._log_error_msg1('to_char()')\n",
    "\n",
    "    def to_pib(self, integer: int, size: int) -> bytes:\n",
    "        if size not in [1, 2, 4, 8]:\n",
    "            self._log_error_msg2(('to_pib()', \"'size' must be one of: 1, 2, 4, or 8.\"))\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            h = hex(integer)[2:]\n",
    "            if len(h) % 2 == 1:\n",
    "                h = '0' + h\n",
    "                \n",
    "            s = int(len(h) / 2)\n",
    "            if s > size:\n",
    "                self._log_error_msg2(('to_pib()', \"'size' not large enough for the 'integer'.\"))\n",
    "                return None\n",
    "            elif s < size:\n",
    "                h = '0' * ((size - s) * 2) + h\n",
    "            \n",
    "            return bytes.fromhex(h)\n",
    "        except:\n",
    "            self._log_error_msg1('to_pib()')\n",
    "            return None\n",
    "        \n",
    "    # Truncated for brevity\n",
    "    \n",
    "E = EBCDIC(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will speed up access to the data during multiple calls\n",
    "records_d = OrderedDict()\n",
    "\n",
    "# Convert a single 'cell' value with the given conversion type\n",
    "def convert_to_ebcdic(value, size, conv, pre):\n",
    "    \n",
    "    pre_b = b''\n",
    "    \n",
    "    if pre != '':\n",
    "        pre_b = E.to_char(pre, len(pre))\n",
    "\n",
    "    if conv == 'CHAR':\n",
    "        if type(value) != str:\n",
    "            value = str(value)\n",
    "        return pre_b + E.to_char(value, size)\n",
    "    \n",
    "    # Truncated \n",
    "    \n",
    "# Map an entire record (row) to a bytes array\n",
    "def map_rec_to_bytes(rec: pd.Series):\n",
    "    \n",
    "    # Get the record layout dict for this record\n",
    "    record_d = records_d[rec['rec_lbl']]\n",
    "    \n",
    "    # Start the binary record\n",
    "    b_rec = b''\n",
    "    \n",
    "    # Mark the current position in the fixed position record\n",
    "    pos = 1\n",
    "    \n",
    "    # Loop through all fields in the layout\n",
    "    for field in record_d.keys():\n",
    "        start = record_d[field]['start']\n",
    "        length = record_d[field]['length']\n",
    "        conversion = record_d[field]['conversion']\n",
    "        \n",
    "        if pos < start:\n",
    "            prepend = ' ' * (start-pos)\n",
    "        else:\n",
    "            prepend = ''\n",
    "        \n",
    "        pos = start + length\n",
    "        \n",
    "        b_rec += convert_to_ebcdic(rec[field], length, conversion, prepend)\n",
    "    \n",
    "    # Add 4 positions for the IBM RDW - minus 1 because pos tracks the position of the next value\n",
    "    rec_len = pos + 4 - 1\n",
    "    \n",
    "    # The IBM RDW is made up of 2 parts\n",
    "    ibm_rdw = E.to_pib(rec_len, 2) + E.to_pib(0, 2)\n",
    "    \n",
    "    return ibm_rdw + b_rec\n",
    "\n",
    "# Map an entire pandas dataframe with the function\n",
    "def map_pandas_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    s = df.apply(\n",
    "        map_rec_to_bytes,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    max_length = s.str.len().max()\n",
    "    \n",
    "    return pd.DataFrame(\n",
    "        [[\n",
    "            b''.join(s.tolist()), max_length\n",
    "        ]],\n",
    "        columns=['Binary Data', 'Rec Length']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data location\n",
    "DATA = 'data'\n",
    "\n",
    "def convert_data(count=5000):\n",
    "    file_path_data = os.path.join(os.getcwd(), DATA, str(count)+'_data.pickle')\n",
    "    file_path_layout = os.path.join(os.getcwd(), DATA, str(count)+'_layout.pickle')\n",
    "    file_path_records = os.path.join(os.getcwd(), DATA, str(count)+'_records.pickle')\n",
    "\n",
    "    with open(file_path_data, 'rb') as f:\n",
    "        data_df = pickle.load(f)\n",
    "    with open(file_path_layout, 'rb') as f:\n",
    "        layout_df = pickle.load(f)\n",
    "    with open(file_path_records, 'rb') as f:\n",
    "        records_df = pickle.load(f)\n",
    "        \n",
    "    # Convert the layout dataframe to dict\n",
    "    # Iterate over each unique record \n",
    "    for record in layout_df['rec'].unique():\n",
    "        fields_d = OrderedDict()\n",
    "        # Iterate over each unique field 'name' in the record\n",
    "        for field in layout_df[layout_df['rec']==record]['name'].unique():\n",
    "            fields_d[field] = layout_df[\n",
    "                (layout_df['rec'] == record) & (layout_df['name'] == field)\n",
    "            ][['start', 'length', 'conversion']].to_dict('records')[0]\n",
    "        records_d[record] = fields_d\n",
    "    \n",
    "    # Add record label to data dataframe\n",
    "    records_l = records_df.values.tolist()\n",
    "    \n",
    "    data_df['rec_lbl'] = ''\n",
    "    \n",
    "    for rec in records_l:\n",
    "        data_df.loc[eval(rec[1]), ['rec_lbl']] = rec[0]\n",
    "\n",
    "    # Start measuring time\n",
    "    pandas_start = time.time()\n",
    "    \n",
    "    # Map the data\n",
    "    pandas_result = map_pandas_df(data_df)\n",
    "    \n",
    "    pandas_secs = time.time() - pandas_start\n",
    "    print(f\"Total time: {pandas_secs:.3f} seconds\")\n",
    "    \n",
    "    return pandas_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 193.637 seconds\n",
      "(1, 2)\n",
      "CPU times: user 3min 16s, sys: 2.11 s, total: 3min 18s\n",
      "Wall time: 3min 18s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Binary Data</th>\n",
       "      <th>Rec Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'\\x00^\\x00\\x00\\xd7\\xd9\\xe2\\xd5@@@@@@\\xf5\\xf8\\...</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Binary Data  Rec Length\n",
       "0  b'\\x00^\\x00\\x00\\xd7\\xd9\\xe2\\xd5@@@@@@\\xf5\\xf8\\...         189"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# df = convert_data(5000)\n",
    "# df = convert_data(50000)\n",
    "df = convert_data(500000)\n",
    "# df = convert_data(5000000)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TR1950\n",
    "- for ~35,000 records --> 2.11 secs\n",
    "- for ~350,000 records --> 19.4 secs\n",
    "- for ~3,500,000 records --> 3 mins 18 secs\n",
    "- for ~35,000,000 records --> Unknown\n",
    "\n",
    "Notes - top shows 100% CPU but low RAM usage\n",
    "\n",
    "Using i7-7700HQ @ 3.54-3.60 GHz\n",
    "\n",
    "- for ~35,000 records --> 3.45 secs\n",
    "- for ~350,000 records --> 35.4 secs\n",
    "- for ~3,500,000 records --> 6 mins 36 secs\n",
    "- for ~35,000,000 records --> 73 mins 29 secs\n",
    "\n",
    "Notes - Task Manager CPU pane shows heavy load on one thread. Other threads show medium to low utilization. Total utilization shows as between 25-29%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
