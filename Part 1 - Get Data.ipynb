{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask DataFrame Experiment\n",
    "\n",
    "## Part 1\n",
    "\n",
    "Get fake data from mimesis for the dataframes that will be used in the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install mimesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimesis import Person, Address, Datetime\n",
    "from mimesis.enums import Gender\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import accumulate\n",
    "\n",
    "# %config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mockup data and accompanying layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = Person('en')\n",
    "address = Address('en')\n",
    "datetime = Datetime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_person():\n",
    "    return {\n",
    "        'rec': 'PRSN',\n",
    "        'id': random.randint(10000, 100000000),\n",
    "        'first_name': person.first_name(),\n",
    "        'last_name': person.last_name(),\n",
    "        'gender': person.gender(),\n",
    "        'ssn': random.randint(1000000, 100000000),\n",
    "    }\n",
    "\n",
    "def generate_address(id, ssn):\n",
    "    return {\n",
    "        'rec': 'ADDR',\n",
    "        'id': id,\n",
    "        'ssn': ssn,\n",
    "        'address': address.address(),\n",
    "        'city': address.city(),\n",
    "        'state': address.state(),\n",
    "        'country': 'USA',\n",
    "        'begin': datetime.date(start=2000, end=2019)\n",
    "    }\n",
    "\n",
    "def generate_email(id, ssn):\n",
    "    return {\n",
    "        'rec': 'EMAL',\n",
    "        'id': id,\n",
    "        'ssn': ssn,\n",
    "        'email': person.email(),\n",
    "        'begin': datetime.date(start=2000, end=2019)\n",
    "    }\n",
    "\n",
    "def create_accounts(num=1):\n",
    "    output = []\n",
    "    for _a in range(num):\n",
    "        p = generate_person()\n",
    "        output.append(p)\n",
    "        for _b in range(random.randint(1, 5)):\n",
    "            output.append(generate_address(p['id'], p['ssn']))\n",
    "        for _c in range(random.randint(1, 5)):\n",
    "            output.append(generate_email(p['id'], p['ssn']))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to create the layout from the generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For padding length of variables to provide 'space' in the final layout\n",
    "def round_up_5(num):\n",
    "    return int(math.ceil(num/5)*5)\n",
    "\n",
    "# Get the length of each column that will fit the max length values and pad for some extra width\n",
    "def create_lengths(df):\n",
    "    d = {}\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            length = df[df[col].notnull()][col].str.len().max()\n",
    "            length = round_up_5(int(length*1.5))\n",
    "        except:\n",
    "            if df[col].dtype == 'O':\n",
    "                length = 10\n",
    "            else:\n",
    "                length = 15\n",
    "        d[col] = length\n",
    "    return d\n",
    "\n",
    "# Convert a record to a layout using the field length information\n",
    "def layout_from_record(d: dict, length_d: dict):\n",
    "    length = [length_d[k] for k in d.keys()]\n",
    "    \n",
    "    return {\n",
    "        'rec': [\"DTL\"+d['rec'] for _ in range(len(d.keys()))],\n",
    "        'name': list(d.keys()),\n",
    "        'start': [x+1 for x in [0]+list(accumulate(length[:-1]))],\n",
    "        'length': length,\n",
    "        'conversion': ['CHAR' for _ in range(len(d.keys()))],\n",
    "    }\n",
    "\n",
    "# Convert a data dataframe to a layout\n",
    "def convert_data_to_layout(df):\n",
    "    # Get the lengths of the data\n",
    "    length_d = create_lengths(df)\n",
    "\n",
    "    # Get the layouts for the 3 records\n",
    "    layout_df = pd.concat([\n",
    "        pd.DataFrame(layout_from_record(generate_person(), length_d)),\n",
    "        pd.DataFrame(layout_from_record(generate_address(1, 2), length_d)),\n",
    "        pd.DataFrame(layout_from_record(generate_email(1, 2), length_d)),\n",
    "    ])\n",
    "\n",
    "    # Make sure the records are sorted correctly\n",
    "    layout_df.sort_values(by=['rec', 'start'], inplace=True)\n",
    "\n",
    "    return layout_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create a record definition table\n",
    "\n",
    "Note -- Based on experience, we 'know' that the \"rec\" column is the column that defines the layout of the data\n",
    "\n",
    "Ideally, this file specification would be stored in a database or other documentation repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a data dataframe to a layout\n",
    "def convert_data_to_record_definitions(df):\n",
    "\n",
    "    # Unique 'rec' values\n",
    "    records = df['rec'].unique().tolist()\n",
    "\n",
    "    # Construct the dataframe definitions from the record 'rec' values\n",
    "    definitions = [\"data_df['rec']=='\" + rec + \"'\" for rec in records]\n",
    "\n",
    "    # Construct the record labels from the record 'rec' values\n",
    "    records = [\"DTL\"+rec for rec in records]\n",
    "\n",
    "    # Zip the 2 lists together into a 'records' definition dataframe\n",
    "    records_df = pd.DataFrame(zip(records, definitions), columns=['Record', 'Definition'])\n",
    "    return records_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the data\n",
    "\n",
    "Generate sets of data starting at 5000 and increasing by an order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data location\n",
    "DATA = 'data'\n",
    "\n",
    "def generate_data(count=5000):\n",
    "    file_path_data = os.path.join(os.getcwd(), DATA, str(count)+'_data.pickle')\n",
    "    file_path_layout = os.path.join(os.getcwd(), DATA, str(count)+'_layout.pickle')\n",
    "    file_path_records = os.path.join(os.getcwd(), DATA, str(count)+'_records.pickle')\n",
    "\n",
    "    data_df = pd.DataFrame(create_accounts(count))\n",
    "    layout_df = convert_data_to_layout(data_df)\n",
    "    records_df = convert_data_to_record_definitions(data_df)\n",
    "    \n",
    "    with open(file_path_data, 'wb') as f:\n",
    "        pickle.dump(data_df, f)\n",
    "    with open(file_path_layout, 'wb') as f:\n",
    "        pickle.dump(layout_df, f)\n",
    "    with open(file_path_records, 'wb') as f:\n",
    "        pickle.dump(records_df, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generate_data(5000)\n",
    "# generate_data(50000)\n",
    "# generate_data(500000)\n",
    "# generate_data(5000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time taken to create the data\n",
    "\n",
    "- 5,000 person accounts takes approx. 0.5 seconds --> 34,932 records\n",
    "- 50,000 person accounts takes approx. 5 seconds --> 350,196 records\n",
    "- 500,000 person accounts takes approx. 57 seconds --> 3,500,295 records\n",
    "- 5,000,000 person accounts takes approx. 1800* seconds --> 34,999,259 records\n",
    "\n",
    "Note - The generation of 5 million person accounts resulted in a RAM limit that slowed down the generation of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5000000_data.pickle',\n",
       " '5000000_layout.pickle',\n",
       " '5000000_records.pickle',\n",
       " '500000_data.pickle',\n",
       " '500000_layout.pickle',\n",
       " '500000_records.pickle',\n",
       " '50000_data.pickle',\n",
       " '50000_layout.pickle',\n",
       " '50000_records.pickle',\n",
       " '5000_data.pickle',\n",
       " '5000_layout.pickle',\n",
       " '5000_records.pickle']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(os.getcwd(), DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
